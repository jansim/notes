#### Unsupervised / Supervised Machine Learning
Unupervised / supervised machine learning refers to whether or not an outcome variable / $Y$ / labels / a ground truth is available. In supervised learning it is, in unsupervised learning it is not.

#### Law of Large Numbers
Back-bone of freq. statistics

#### Selection Bias
Error due to non-random sample from population

#### Survivorship Bias
Non-random dropout leading to weird sample.

#### One-hot encoding / Dummy coding
Turn categorical variables into numerical ones.

#### Cold-Start Problem

#### Gini Index
TODO

#### Eigenvector
TODO

#### Eigenvalue
TODO

#### Gaussian Mixture Models
TODO

#### Least Squares
TODO

#### Gradient Descent
TODO

#### Hyperparameters
Parameters of a model that can not be estimated by the model itself (aka Tuning Parameters). Typically picked either using heuristics / conventions or by using a search method e.g. grid search using cross validation.

Other examples of search methods: genetic algorithms, Bayesian search.

#### Euclidean Distance
Measure of distance between vectors / points. Square-root of squared differences between all coordinates.

$Euclidean Distance = \sqrt{\sum{(x_{i} - x_{i+1})^2}}$

#### Features
Input to machine learning models ($X$), sometimes also called predictors. the crucial process of optimizing, generating and picking features is called *feature engineering*.

#### Labels
Typically refers to the outcome ($Y$) i.e. the variable we want to predict with our machine learning model.

