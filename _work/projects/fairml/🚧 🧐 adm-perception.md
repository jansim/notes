#adm-perception 


## Other

- Suggestion-generating / supporting models e.g. DB or Lufthansa @ German data science days 2023
- Counterfactuals
	- https://github.com/dandls/counterfactuals
	- https://www.microsoft.com/en-us/research/project/dice/


## Notes 2023-05-23
- unterliegende Theorien
- Ein gut verst√§ndliches Szenario genauer anschauen f√ºr zB H-I-L oder eigene Betroffenheit
- Basierend auf Theorie?
- klare Idee √ºber Mechanismus, die auch beschrieben werden Kann
- Was w√ºrden wir dabei lernen?
- Algorithmen -> objektivisierung
	- Favors those w/ more
- Felt power of questining authority? Accepting authority?
- Selbstwirksamkeit
- M√∂glichkeit zu beeinflussen
- Verwendung von ChatGPT detectors?
- Elternbildung in Schul success prediciton model
- 

## Papers to add

### prio 1 ü§©
- [ ] Xinru Wang, Zhuoran Lu, and Ming Yin. 2022. Will You Accept the AI Recommendation? Predicting Human Behavior in AI-Assisteed Decision Making. In Proceedings of the ACM Web Conference 2022. 1697‚Äì1708.
- [ ] 
- [ ] Kazuo Okamura and Seiji Yamada. 2020. Adaptive trust calibration for human-AI collaboration. Plos one 15, 2 (2020), e0229132.
- [ ] Berkeley Dietvorst, Joseph Simmons, and Cade Massey. 2018. Overcoming Algorithm Aversion: People Will Use Imperfect Algorithms If They Can (Even Slightly) Modify Them. Management Science 64 (03 2018), 1155‚Äì1170. https://doi.org/10.1287/mnsc.2016.2643
- [ ] Omri Gillath, Ting Ai, Michael S. Branicky, Shawn Keshmiri, Robert B. Davison, and Ryan Spaulding. 2021. Attachment and trust in artificial intelligence. Computers in Human Behavior 115 (2021), 106607. https://doi.org/10.1016/j.chb.2020. 106607
- [ ] Zhuoran Lu and Ming Yin. 2021. Human Reliance on Machine Learning Models When Performance Feedback is Limited: Heuristics and Risks. In Proceedings of the 2021 CHI Conference on Human Factors in Computing Systems. 1‚Äì16.
- [ ] Forough Poursabzi-Sangdeh, Daniel G Goldstein, Jake M Hofman, Jennifer Wortman Wortman Vaughan, and Hanna Wallach. 2021. Manipulating and measuring model interpretability. In Proceedings of the 2021 CHI conference on human factors in computing systems. 1‚Äì52.
- [ ] Yunfeng Zhang, Q Vera Liao, and Rachel KE Bellamy. 2020. Effect of confidence and explanation on accuracy and trust calibration in AI-assisted decision making. In Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency. 295‚Äì305.
- [ ] Ming Yin, Jennifer Wortman Vaughan, and Hanna Wallach. 2019. Understanding the effect of accuracy on trust in machine learning models. In Proceedings of the 2019 chi conference on human factors in computing systems. 1‚Äì12.


### prio 2 üôÇ
- [ ] Chun-Wei Chiang and Ming Yin. 2021. You‚Äôd Better Stop! Understanding Human Reliance on Machine Learning Models under Covariate Shift. In 13th ACM Web Science Conference 2021. 120‚Äì129.
- [ ] Amy Rechkemmer and Ming Yin. 2022. When Confidence Meets Accuracy: Exploring the Effects of Multiple Performance Indicators on Trust in Machine Learning Models. In CHI Conference on Human Factors in Computing Systems. 1‚Äì14.
- [ ] Stephanie M Merritt. 2011. Affective processes in human‚Äìautomation interactions. Human Factors 53, 4 (2011), 356‚Äì370.


## Personal Notes

Ideal outcome: Actionable information on how to create ADM system

- Trust <-> Fairness?

- Trust
	- Accuracy -> Trust (Yin et al., 2019)
	- Fairness -> Trust (Zhou et al., 2021)
	- Scales
		- 6 items x 5 Likert opts (Merritt et al., 2013)
			- used by (Zhou et al., 2021)
		- 
	
- Fairness

> Fairness heuristic theory [23, 34] suggests that when individuals face uncertain circumstances they rely on impressions of fairness to determine whether to cooperate and enter into exchange relationships with the other party, which suggests that individuals use fairness judgements to form their perceptions of trust. (Zhou et al., 2021)


oft human vs machine
was ist mit human in the loop?

Potentially good one:
‚ÄºÔ∏è human in the loop als betroffener vs human in the loop als entscheidungsfinder !!