## Abstract (v2)

Over the last few years the importance of algorithmic fairness in machine learning has gathered more and more traction and developed into a flourishing field of study. However, there still exists a gap between theoretic research on algorithmic fairness and its implementation in practice. Here, we show the importance of addressing this gap by demonstrating how algorithmic fairness heavily depends on the decisions made during a systems’ design and implementation, as biases in data can be mitigated or reinforced along the typical modeling pipeline. We present a framework that can aide in the design of robust real-world applications and help to inform the future study of algorithmic fairness.
Drawing on insights from the field of psychology, we introduce the method of multiverse analysis for algorithmic fairness. In our proposed method, we turn implicit design decisions into explicit ones and demonstrate their implications on fairness. By combining decisions, we create a grid of all possible “universes” of decision combinations. Using the resulting dataset, we can see how and which decisions impact fairness. We demonstrate how multiverse analyses can be used to better understand variability and robustness of algorithmic fairness using an exemplary case study of predicting public health care coverage of vulnerable populations for potential interventions.

## Abstract (v1)
Over the last few years the importance of algorithmic fairness in machine learning has gathered more and more traction and developed into a flourishing field of study. However, in real world applications a lack of fairness or disregard of its importance is still commonplace, as can be seen from frequent news issues of ill-designed systems. This is especially problematic in the context of algorithmic decision making (ADM) where decisions that have previously been made by humans are instead automated. Here, we demonstrate that algorithmic fairness heavily depends on the decisions made during a systems’ design and implementation, as biases in data can be mitigated or reinforced along the modeling pipeline. We present a framework that can aide in the design of robust real-world applications of algorithmic fairness and inform the future study of algorithmic fairness.
Drawing on insights from the field of psychology, we introduce the method of multiverse analysis for algorithmic fairness. In our proposed method, we turn implicit design decisions into explicit ones and demonstrate their fairness implications. By combining decisions, we create a grid of all possible “universes” of decision combinations. Using the resulting dataset, we can see how and which decisions impact fairness. We demonstrate how multiverse analyses can be used to better understand variability and robustness of algorithmic fairness using an exemplary case study of predicting public health coverage of vulnerable populations for potential interventions.
