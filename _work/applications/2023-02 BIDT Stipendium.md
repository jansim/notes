http://www.bidt.digital/foerderprogramm/graduate-center-fuer-promovierende/
## Inhalt
Eine Bewerbung muss folgende Unterlagen umfassen:

-   ausgefülltes [Bewerbungsformular](https://de.bidt-main.de/wp-content/uploads/sites/2/2022/11/Bewerbungsformular_Promovierende.pdf) einschließlich der Beschreibung des Promotionsvorhabens; das Promotionsvorhaben soll einen für die Digitalisierung bedeutenden technischen, wirtschaftlichen oder gesellschaftlichen Fokus haben und auf die Dauer von bis zu vier Jahren angelegt sein
-   Lebenslauf einschließlich Zeugnisse
-   Nachweis über einen hervorragenden Hochschulabschluss oder vergleichbaren staatlich anerkannten Studienabschluss, der zur Promotion an einer Hochschule qualifiziert
-   Formlose Erklärung durch die betreuende Hochschullehrerin oder den betreuenden Hochschullehrer über die Betreuung und die Unterstützung dieser Bewerbung

Vollständige Bewerbungsunterlagen (Bewerbungsformular mit Promotionsvorhaben, Lebenslauf und Zeugnisse, Unterstützungserklärung) sind in einem einzigen PDF-Dokument (maximal 7 MB) an [young-talents@bidt.digital](mailto:young-talents@bidt.digital) zu senden.

- 2 focus areas: Alignment of AI; Understanding of AI Systems (more robust, reliable)
- Fairness perceptions in ADM -> better alignment
- Multiverse -> more robust


### Working Title of the Dissertation

Improving the Understanding of Algorithmic Decision Making and the Human Perception

Algorithmic Decision Making: Understanding its Perception

Algorithmic Decision Making and Fairness: Insights into its Inner Workings

Insights into the Design of Fair Algorithmic Decision Making

Fair Algorithmic Decision Making: New Perspectives and Methodologies

**Methods and Insights for the Design of Fair and Trustworthy Algorithmic Decision Making**

### Societal Relevance
> Please expound how your proposed research project relates to issues of digitalisation? Which technically, economically, or socially relevant results do you expect? Which further research questions may evolve from these? (ca. 1/2 page, 200 words)

We're currently amidst a massive ongoing digital transformation coming from the field of artificial intelligence.

- AI everywhere is coming whether we like it or not, one particular important part: ADM (many examples in the wild; maybe also factor in "assisstants i.e. ChatGPT")
- better insights into what makes people trust AI (and ADM) systems -> alignment
- improve reliability / robustness of these systems

**Text:**

One aspect of the digital transformation that has already significantly impacted the world, is the rise of artificial intelligence and machine learning systems used in decision making. These systems either inform or completely automate a decision previously made by a human, in what is referred to as algorithmic decision making (ADM). Plenty of examples of ADM being used in the wild can be found to date across the world, within Europe, Germany, and Bavaria.

When designed well, these systems promise both more accurate and more efficient decisions all the while freeing up human time. When ADM systems are not designed well, however, they can lead to unfair algorithms which discriminate against parts of the population under the guise of objectivity and legitimacy. Ample examples exist of unfair ADM systems discriminating against people in the wild, with the discriminatory Dutch childcare benefits system being an especially prominent and recent example.

My research aims to improve both our understanding of the interaction between humans and ADM systems and the methodology we have available to understand the systems themselves. The resulting knowledge can inform the design of future ADM systems and improve the alignment between these systems and human interests.

### Brief summary of dissertation proposal
> Please provide a brief and clearly understandable description of your dissertation project. Among other things, address which types of methodology your research exhibits (e.g. qualitative research, algorithms, sensors and measured data, textual analysis, etc.) (max. 1 page, 300 words).


I plan to research the fairness of machine learning and ADM systems using two complementary avenues of research: (1) better understanding people's perspectives on fairness in ADM systems and (2) improving the available methodology to study these systems.

First, I plan to study how people perceive an ADM system's decisions if they would be impacted by it themselves. I will study this question using a large-scale vignette study where aspects of the ADM system (e.g. it's accuracy or fairness measures), the way it is communicated (e.g. different degrees of explanations) and the decision itself (e.g. whether one receives positive or negative decision) will be varied. The first study on this topic will be using a paid, representative sample from Germany. Additionally, I am hoping to run a study with a similar design at a larger scale, building on my successful experience using citizen science and gamification in the past.

The second part of my dissertation project will be to introduce and develop new methodologies for analysing fairness in machine learning systems. In particular, I am currently adapting multiverse analyses, a novel method first introduced in Psychology by Steegen et al. to improve reproducibility. During the creation and design of an ADM system one needs to make a multitude of decisions. Many of these decisions are made implicitly without knowing exactly how they will impact the final system and whether it will lead to fair decisions. With the proposed method these implicit decisions made during the design of an ADM system are turned into explicit ones. Using a grid of all possible ”universes” of decision-combinations, one can compute measures of fairness for each. The resulting dataset can be analysed to see how and which decisions impact fairness, with surprising as well as promising preliminary results.




# Previous Drafts (too long)

### Societal Relevance
> Please expound how your proposed research project relates to issues of digitalisation? Which technically, economically, or socially relevant results do you expect? Which further research questions may evolve from these? (ca. 1/2 page, 200 words)

We're currently amidst a massive ongoing digital transformation coming from the field of artificial intelligence.

- AI everywhere is coming whether we like it or not, one particular important part: ADM (many examples in the wild; maybe also factor in "assisstants i.e. ChatGPT")
- better insights into what makes people trust AI (and ADM) systems -> alignment
- improve reliability / robustness of these systems

**Text:**

One aspect of digital transformations that has already significantly impacted the world, is the rise of artificial intelligence and machine learning systems used in decision making. These systems either inform or completely automate a decision previously made by a human, in what's commonly referred to as algorithmic decision making (ADM). Plenty of examples of ADM being used in the wild can be found to date across the world, within Europe, in Germany and in Bavaria.

When designed well, these systems promise both more accurate and more efficient decisions all the while saving resources and freeing up human time. When ADM systems are not designed well, however, they can lead to unfair algorithms which discriminate against parts of the population under the guise of objectivity and legitimacy. Ample examples exist of unfair ADM systems discriminating against people in the wild, with the Dutch childcare benefits system being an especially prominent and recent example.

My research aims to improve our understanding of these ADM systems. First, I plan to better understand the factors that govern whether or not people trust decisions made by - or with the help of - algorithms and when they perceive them as fair or unfair. This knowledge can inform the design of future ADM systems and improve the alignment between ADM systems and human interests.

Second, my research will improve our understanding of the factors that influence an ADM systems objective fairness. When creating ADM systems we often have to work with biased and unfair data sources, with new collection being unfeasible. Whether or not an ADM system can mitigate the biases present in the data or will reinforce them is therefore dependent on the choices made during its design. Unfortunately many of these choices are being made implicitly without awareness of their importance and possible repercussions. My research will demonstrate the importance of ADM design decisions and which of them matter by proposing a new methodology for their study.

(Zu applied, more general!)

### Brief summary of dissertation proposal
> Please provide a brief and clearly understandable description of your dissertation project. Among other things, address which types of methodology your research exhibits (e.g. qualitative research, algorithms, sensors and measured data, textual analysis, etc.) (max. 1 page, 300 words).


The overarching question I plan to answer in my dissertation is XYZ. I plan to do this using two complementary avenues of research: better understanding people's perspectives on fairness in ADM and improving the available methodology.

First, I plan to study how people perceive an ADM system's decisions if they would be impacted by it themselves. I will study this question using a large-scale vignette study where aspects of the ADM system (e.g. it's scores on accuracy and different measures of fairness), the way it is communicated (e.g. different degrees of explanations) and the decision itself (e.g. whether one receives positive or negative decision) will be varied. Our first study on this topic will be using a paid, representative participant pool from Germany. Besides this data collection, I am hoping to run a study with a similar design at a larger scale, building on my successful experience using citizen science and gamification in the past. This could allow us to analyse this question beyond the scope of so-called WEIRD populations, which have been predominantly used in the fairness literature so far.

The second part of my dissertation project will be to introduce and develop new methodologies for analysing fairness in machine learning systems, with a particular focus on ADM systems. In particular I am working on adapting multiverse analyses, a new method first introduced in Psychology by Steegen et al. in 2016 to improve reproducibility. During the creation and design of an ADM system one needs to make a multitude of different decisions. Many of these decisions are made implicitly without knowing exactly how they will impact the final system and whether or not it will lead to fair decisions. In the proposed adaptation of multiverse analysis for ADM we plan to turn these implicit decisions made during the design of an ADM system into explicit ones.  Using the resulting decision space, I create a grid of all possible ”universes” of decision-combinations. For each of these universes, the fairness of the ADM system is computed. I will analyse the resulting dataset of possible decisions and fairness to see how and which decisions impact fairness.
