  
  

ABSTRACT:

  

"systems" -> it would be good to specify what types of systems and the notion of automation in this context (a few phrases would be good)

  

"objective decisions" -> what do you mean by objective?

  

"large amounts of resources and freeing up human time" -> how? What is the resource in this context?

  

"unfair decisions" -> if this is what you want, you should probably say this much earlier

  

"as biases in data can be mitigated" -> are you now assuming that the systems use data? It is a bit confusing now

  

"decisions" -> this word is used in two ways; one is for the decisions for designing the systems; the others are decisions for generating societal outcomes; please make sure you don't confuse the readers

  

"multiverse analysis" -> It would be good to have a few-word description of this

  

The notion of fairness here isn't really clear at this point

  

1 INTRODUCTION

  

"Examples of such systems can be found in finance" -> it would be good to provide some concrete examples of how ML/algorithms actually use to make decisions

  

"when designed wrongly" -> wrong seems to be too strong because it depends on the contexts and criteria

  

"on the accused to prove the contrary" -> I am a bit confused; why is this an issue?

  

"the Dutch childcare benefits system" -> what does this do? How does it relate to detecting fraud?

  

"the underlying training data" -> this depends on the types of systems you are interested in

  

"provide modular source code" -> is this publicly available?

  

1.1 Multiverse Analysis

  

The main question is how do you generate different sub-datasets from the given grand dataset? I would imagine this is very computationally expensive

  

"of the effect size or coefficient" -> not clear how curve analysis is related to multiverse analysis; what is the purpose of bring this concept here?

  

1.2 Multiverse Analysis for Algorithmic Fairness

  

How many decision points are enough to evaluate the robustness of a given system? I would imagine there will be an instance in which the system will be unfair no matter what (e.g., a single data point)

  
  

1.3 Case Study

  

"predicting public health insurance coverage" -> is this at an individual level? So if you can predict whether a person has health insurance, then you can try to get them to get it? What intervention can you do for this?

  

"due to not understanding how it works ..." -> Isn't this also due to financial issues? But isn't these people covered under social security/government?

  

What does fairness mean in this context?

  

For the results here, do you have some breakdown of specific classifiers?

  

SEPARATE POINT