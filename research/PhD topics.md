## Re-Evaluating the Machine Learning Pipeline to Improve Fairness and Reliability

Fairness in machine learning continues to be a highly relevant issue, with unfair models making headlines on a regular basis. In this project, we re-evaluate the complete machine learning pipeline from the sourcing of data, over the design of ML systems all the way to their implementation with an eye on algorithmic fairness and robustness. We develop new methodologies and collect data to better understand the reliability of findings in the field. We further critically examine the usage and composition of datasets, highlighting gaps and providing recommendations for more sustainable practices. Among other things, we focus on the influence of design decisions, highlighting potential issues of fairness hacking and introducing a new methodology to systematically study and address issues of reliability.
## Other
- Accessibility of statistics
-  Democratizing Data Science
	- More Intuitive Statistics
- Bridging the Gap between Intended and Actual Behaviour
- Emotion Research Tooling
	- Pupillometry
- Open Data?
- resilience to influence
- Data Quality
	- in regards to fairness / bias in the data
	- representation
	- building tools to easily examine this?
	- 